{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/codespace/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('punkt') \n",
    "from nltk.tokenize import word_tokenize\n",
    "import fitz  \n",
    "import requests\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('/workspaces/Wikistim-Summarization/00_source_data/completed_papers_wikistim.csv')\n",
    "data_with_url = raw_data[~raw_data['Full text link'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download PDFS from url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5232/3820561139.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_with_url['Downloaded PDF Path'] = \"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded PDF 0 to /workspaces/Wikistim-Summarization/00_source_data/downloaded_pdfs/pdf_0.pdf\n",
      "Downloaded PDF 1 to /workspaces/Wikistim-Summarization/00_source_data/downloaded_pdfs/pdf_1.pdf\n",
      "Downloaded PDF 3 to /workspaces/Wikistim-Summarization/00_source_data/downloaded_pdfs/pdf_3.pdf\n",
      "Failed to download PDF 4 from URL http://onlinelibrary.wiley.com/doi/10.1111/ner.12746/epdf. Status Code: 403\n",
      "Failed to download PDF 4 from URL http://onlinelibrary.wiley.com/doi/10.1111/ner.12746/epdf. Status Code: 403\n",
      "Failed to download PDF 4 from URL http://onlinelibrary.wiley.com/doi/10.1111/ner.12746/epdf. Status Code: 403\n",
      "Maximum retry count reached for PDF 4. Download failed.\n",
      "Downloaded PDF 5 to /workspaces/Wikistim-Summarization/00_source_data/downloaded_pdfs/pdf_5.pdf\n",
      "Downloaded PDF 6 to /workspaces/Wikistim-Summarization/00_source_data/downloaded_pdfs/pdf_6.pdf\n",
      "Failed to download PDF 7 from URL https://www.jpsmjournal.com/article/S0885-3924(96)00322-3/pdf. Status Code: 403\n",
      "Failed to download PDF 7 from URL https://www.jpsmjournal.com/article/S0885-3924(96)00322-3/pdf. Status Code: 403\n",
      "Failed to download PDF 7 from URL https://www.jpsmjournal.com/article/S0885-3924(96)00322-3/pdf. Status Code: 403\n",
      "Maximum retry count reached for PDF 7. Download failed.\n",
      "Downloaded PDF 11 to /workspaces/Wikistim-Summarization/00_source_data/downloaded_pdfs/pdf_11.pdf\n",
      "Downloaded PDF 14 to /workspaces/Wikistim-Summarization/00_source_data/downloaded_pdfs/pdf_14.pdf\n",
      "Downloaded PDF 15 to /workspaces/Wikistim-Summarization/00_source_data/downloaded_pdfs/pdf_15.pdf\n",
      "Downloaded PDF 17 to /workspaces/Wikistim-Summarization/00_source_data/downloaded_pdfs/pdf_17.pdf\n",
      "Downloaded PDF 19 to /workspaces/Wikistim-Summarization/00_source_data/downloaded_pdfs/pdf_19.pdf\n",
      "Downloaded PDF 20 to /workspaces/Wikistim-Summarization/00_source_data/downloaded_pdfs/pdf_20.pdf\n",
      "Downloaded PDF 21 to /workspaces/Wikistim-Summarization/00_source_data/downloaded_pdfs/pdf_21.pdf\n",
      "Downloaded PDF 23 to /workspaces/Wikistim-Summarization/00_source_data/downloaded_pdfs/pdf_23.pdf\n",
      "Downloaded PDF 25 to /workspaces/Wikistim-Summarization/00_source_data/downloaded_pdfs/pdf_25.pdf\n",
      "Downloaded PDF 27 to /workspaces/Wikistim-Summarization/00_source_data/downloaded_pdfs/pdf_27.pdf\n",
      "Failed to download PDF 28 from URL http://cep.sagepub.com/content/30/3/260.full.pdf. Status Code: 403\n",
      "Failed to download PDF 28 from URL http://cep.sagepub.com/content/30/3/260.full.pdf. Status Code: 403\n",
      "Failed to download PDF 28 from URL http://cep.sagepub.com/content/30/3/260.full.pdf. Status Code: 403\n",
      "Maximum retry count reached for PDF 28. Download failed.\n",
      "Downloaded PDF 29 to /workspaces/Wikistim-Summarization/00_source_data/downloaded_pdfs/pdf_29.pdf\n",
      "Downloaded PDF 35 to /workspaces/Wikistim-Summarization/00_source_data/downloaded_pdfs/pdf_35.pdf\n",
      "Downloaded PDF 36 to /workspaces/Wikistim-Summarization/00_source_data/downloaded_pdfs/pdf_36.pdf\n",
      "Downloaded PDF 46 to /workspaces/Wikistim-Summarization/00_source_data/downloaded_pdfs/pdf_46.pdf\n",
      "Downloaded PDF 51 to /workspaces/Wikistim-Summarization/00_source_data/downloaded_pdfs/pdf_51.pdf\n",
      "Downloaded PDF 53 to /workspaces/Wikistim-Summarization/00_source_data/downloaded_pdfs/pdf_53.pdf\n",
      "Downloaded PDF 62 to /workspaces/Wikistim-Summarization/00_source_data/downloaded_pdfs/pdf_62.pdf\n",
      "Failed to download PDF 67 from URL https://reader.elsevier.com/reader/sd/pii/0735109794906610?token=7E8B69BBB6C7AA68245C65E74EA843EB180B3DF260BD233E11FC49CA2104D0D53E4AC4930A0E45B93DEE1AE9BC703B5F&originRegion=us-east-1&originCreation=20210422183155. Status Code: 403\n",
      "Failed to download PDF 67 from URL https://reader.elsevier.com/reader/sd/pii/0735109794906610?token=7E8B69BBB6C7AA68245C65E74EA843EB180B3DF260BD233E11FC49CA2104D0D53E4AC4930A0E45B93DEE1AE9BC703B5F&originRegion=us-east-1&originCreation=20210422183155. Status Code: 403\n",
      "Failed to download PDF 67 from URL https://reader.elsevier.com/reader/sd/pii/0735109794906610?token=7E8B69BBB6C7AA68245C65E74EA843EB180B3DF260BD233E11FC49CA2104D0D53E4AC4930A0E45B93DEE1AE9BC703B5F&originRegion=us-east-1&originCreation=20210422183155. Status Code: 403\n",
      "Maximum retry count reached for PDF 67. Download failed.\n",
      "Downloaded PDF 68 to /workspaces/Wikistim-Summarization/00_source_data/downloaded_pdfs/pdf_68.pdf\n",
      "Downloaded PDF 70 to /workspaces/Wikistim-Summarization/00_source_data/downloaded_pdfs/pdf_70.pdf\n",
      "Downloaded PDF 77 to /workspaces/Wikistim-Summarization/00_source_data/downloaded_pdfs/pdf_77.pdf\n",
      "Failed to download PDF 82 from URL https://www.nejm.org/doi/pdf/10.1056/NEJM200008313430904?articleTools=true. Status Code: 403\n",
      "Failed to download PDF 82 from URL https://www.nejm.org/doi/pdf/10.1056/NEJM200008313430904?articleTools=true. Status Code: 403\n",
      "Failed to download PDF 82 from URL https://www.nejm.org/doi/pdf/10.1056/NEJM200008313430904?articleTools=true. Status Code: 403\n",
      "Maximum retry count reached for PDF 82. Download failed.\n",
      "Downloaded PDF 91 to /workspaces/Wikistim-Summarization/00_source_data/downloaded_pdfs/pdf_91.pdf\n",
      "Downloaded PDF 102 to /workspaces/Wikistim-Summarization/00_source_data/downloaded_pdfs/pdf_102.pdf\n",
      "Downloaded PDF 104 to /workspaces/Wikistim-Summarization/00_source_data/downloaded_pdfs/pdf_104.pdf\n",
      "Downloaded PDF 106 to /workspaces/Wikistim-Summarization/00_source_data/downloaded_pdfs/pdf_106.pdf\n",
      "Failed to download PDF 110 from URL https://www.minervamedica.it/en/getfreepdf/YmZDMnk5VW1rRTV0dVBqWFlYL2dOeHAzcUVHUUJSNVAreE5aVjZxZlUxeHNZZ1ZrRzlzNkx2TG1ydmJSeFEvcA%253D%253D/R02Y2012N03A0297.pdf. Status Code: 302\n",
      "Failed to download PDF 110 from URL https://www.minervamedica.it/en/getfreepdf/YmZDMnk5VW1rRTV0dVBqWFlYL2dOeHAzcUVHUUJSNVAreE5aVjZxZlUxeHNZZ1ZrRzlzNkx2TG1ydmJSeFEvcA%253D%253D/R02Y2012N03A0297.pdf. Status Code: 302\n",
      "Failed to download PDF 110 from URL https://www.minervamedica.it/en/getfreepdf/YmZDMnk5VW1rRTV0dVBqWFlYL2dOeHAzcUVHUUJSNVAreE5aVjZxZlUxeHNZZ1ZrRzlzNkx2TG1ydmJSeFEvcA%253D%253D/R02Y2012N03A0297.pdf. Status Code: 302\n",
      "Maximum retry count reached for PDF 110. Download failed.\n",
      "Successfully downloaded 35 out of 35 papers (100.00% success rate)\n"
     ]
    }
   ],
   "source": [
    "download_dir = \"/workspaces/Wikistim-Summarization/00_source_data/downloaded_pdfs\"\n",
    "os.makedirs(download_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "user_agent = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36\"\n",
    "\n",
    "max_retries = 3\n",
    "\n",
    "data_with_url['Downloaded PDF Path'] = \"\"\n",
    "\n",
    "\n",
    "for idx, url in data_with_url['Full text link'].items():\n",
    "    retry_count = 0\n",
    "    while retry_count < max_retries:\n",
    "        try:\n",
    "            headers = {\"User-Agent\": user_agent}\n",
    "            response = requests.get(url, headers=headers, timeout=30)\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                # Define the filename based on the index\n",
    "                filename = f\"pdf_{idx}.pdf\"\n",
    "                # Define the full path to save the file\n",
    "                file_path = os.path.join(download_dir, filename)\n",
    "                \n",
    "                # Save the PDF to the specified directory with the indexed filename\n",
    "                with open(file_path, 'wb') as pdf_file:\n",
    "                    pdf_file.write(response.content)\n",
    "                \n",
    "                # Update the DataFrame with the downloaded PDF path\n",
    "                data_with_url.at[idx, 'Downloaded PDF Path'] = file_path\n",
    "                \n",
    "                print(f\"Downloaded PDF {idx} to {file_path}\")\n",
    "                break  # Successful download, exit retry loop\n",
    "            else:\n",
    "                print(f\"Failed to download PDF {idx} from URL {url}. Status Code: {response.status_code}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading PDF {idx} from URL {url}: {e}\")\n",
    "        \n",
    "        # Increment the retry count and wait before the next retry\n",
    "        retry_count += 1\n",
    "        time.sleep(5)  # Wait for 5 seconds before retrying\n",
    "\n",
    "    if retry_count >= max_retries:\n",
    "        print(f\"Maximum retry count reached for PDF {idx}. Download failed.\")\n",
    "\n",
    "\n",
    "# Calculate the number of successfully downloaded papers\n",
    "successful_downloads = data_with_url['Downloaded PDF Path'].count()\n",
    "\n",
    "# Calculate the total number of papers\n",
    "total_papers = len(data_with_url)\n",
    "\n",
    "# Calculate the percentage of successful downloads\n",
    "success_percentage = (successful_downloads / total_papers) * 100\n",
    "\n",
    "# Print the result\n",
    "print(f\"Successfully downloaded {successful_downloads} out of {total_papers} papers ({success_percentage:.2f}% success rate)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded PDF 0 to /workspaces/Wikistim-Summarization/00_source_data/downloaded_pdfs/pdf_0.pdf\n",
      "Downloaded PDF 1 to /workspaces/Wikistim-Summarization/00_source_data/downloaded_pdfs/pdf_1.pdf\n",
      "Downloaded PDF 3 to /workspaces/Wikistim-Summarization/00_source_data/downloaded_pdfs/pdf_3.pdf\n",
      "Failed to download PDF 4 from URL http://onlinelibrary.wiley.com/doi/10.1111/ner.12746/epdf. Status Code: 403\n",
      "Failed to download PDF 4 from URL http://onlinelibrary.wiley.com/doi/10.1111/ner.12746/epdf. Status Code: 403\n",
      "Failed to download PDF 4 from URL http://onlinelibrary.wiley.com/doi/10.1111/ner.12746/epdf. Status Code: 403\n",
      "Maximum retry count reached for PDF 4. Download failed.\n",
      "Downloaded PDF 5 to /workspaces/Wikistim-Summarization/00_source_data/downloaded_pdfs/pdf_5.pdf\n",
      "Downloaded PDF 6 to /workspaces/Wikistim-Summarization/00_source_data/downloaded_pdfs/pdf_6.pdf\n",
      "Failed to download PDF 7 from URL https://www.jpsmjournal.com/article/S0885-3924(96)00322-3/pdf. Status Code: 403\n",
      "Failed to download PDF 7 from URL https://www.jpsmjournal.com/article/S0885-3924(96)00322-3/pdf. Status Code: 403\n",
      "Failed to download PDF 7 from URL https://www.jpsmjournal.com/article/S0885-3924(96)00322-3/pdf. Status Code: 403\n",
      "Maximum retry count reached for PDF 7. Download failed.\n",
      "Downloaded PDF 11 to /workspaces/Wikistim-Summarization/00_source_data/downloaded_pdfs/pdf_11.pdf\n",
      "Downloaded PDF 14 to /workspaces/Wikistim-Summarization/00_source_data/downloaded_pdfs/pdf_14.pdf\n",
      "Downloaded PDF 15 to /workspaces/Wikistim-Summarization/00_source_data/downloaded_pdfs/pdf_15.pdf\n",
      "Downloaded PDF 17 to /workspaces/Wikistim-Summarization/00_source_data/downloaded_pdfs/pdf_17.pdf\n",
      "Downloaded PDF 19 to /workspaces/Wikistim-Summarization/00_source_data/downloaded_pdfs/pdf_19.pdf\n",
      "Downloaded PDF 20 to /workspaces/Wikistim-Summarization/00_source_data/downloaded_pdfs/pdf_20.pdf\n",
      "Downloaded PDF 21 to /workspaces/Wikistim-Summarization/00_source_data/downloaded_pdfs/pdf_21.pdf\n",
      "Downloaded PDF 23 to /workspaces/Wikistim-Summarization/00_source_data/downloaded_pdfs/pdf_23.pdf\n",
      "Downloaded PDF 25 to /workspaces/Wikistim-Summarization/00_source_data/downloaded_pdfs/pdf_25.pdf\n",
      "Downloaded PDF 27 to /workspaces/Wikistim-Summarization/00_source_data/downloaded_pdfs/pdf_27.pdf\n",
      "Failed to download PDF 28 from URL http://cep.sagepub.com/content/30/3/260.full.pdf. Status Code: 403\n",
      "Failed to download PDF 28 from URL http://cep.sagepub.com/content/30/3/260.full.pdf. Status Code: 403\n",
      "Failed to download PDF 28 from URL http://cep.sagepub.com/content/30/3/260.full.pdf. Status Code: 403\n",
      "Maximum retry count reached for PDF 28. Download failed.\n",
      "Downloaded PDF 29 to /workspaces/Wikistim-Summarization/00_source_data/downloaded_pdfs/pdf_29.pdf\n",
      "Downloaded PDF 35 to /workspaces/Wikistim-Summarization/00_source_data/downloaded_pdfs/pdf_35.pdf\n",
      "Downloaded PDF 36 to /workspaces/Wikistim-Summarization/00_source_data/downloaded_pdfs/pdf_36.pdf\n",
      "Downloaded PDF 46 to /workspaces/Wikistim-Summarization/00_source_data/downloaded_pdfs/pdf_46.pdf\n",
      "Downloaded PDF 51 to /workspaces/Wikistim-Summarization/00_source_data/downloaded_pdfs/pdf_51.pdf\n",
      "Downloaded PDF 53 to /workspaces/Wikistim-Summarization/00_source_data/downloaded_pdfs/pdf_53.pdf\n",
      "Downloaded PDF 62 to /workspaces/Wikistim-Summarization/00_source_data/downloaded_pdfs/pdf_62.pdf\n",
      "Failed to download PDF 67 from URL https://reader.elsevier.com/reader/sd/pii/0735109794906610?token=7E8B69BBB6C7AA68245C65E74EA843EB180B3DF260BD233E11FC49CA2104D0D53E4AC4930A0E45B93DEE1AE9BC703B5F&originRegion=us-east-1&originCreation=20210422183155. Status Code: 403\n",
      "Failed to download PDF 67 from URL https://reader.elsevier.com/reader/sd/pii/0735109794906610?token=7E8B69BBB6C7AA68245C65E74EA843EB180B3DF260BD233E11FC49CA2104D0D53E4AC4930A0E45B93DEE1AE9BC703B5F&originRegion=us-east-1&originCreation=20210422183155. Status Code: 403\n",
      "Failed to download PDF 67 from URL https://reader.elsevier.com/reader/sd/pii/0735109794906610?token=7E8B69BBB6C7AA68245C65E74EA843EB180B3DF260BD233E11FC49CA2104D0D53E4AC4930A0E45B93DEE1AE9BC703B5F&originRegion=us-east-1&originCreation=20210422183155. Status Code: 403\n",
      "Maximum retry count reached for PDF 67. Download failed.\n",
      "Downloaded PDF 68 to /workspaces/Wikistim-Summarization/00_source_data/downloaded_pdfs/pdf_68.pdf\n",
      "Downloaded PDF 70 to /workspaces/Wikistim-Summarization/00_source_data/downloaded_pdfs/pdf_70.pdf\n",
      "Downloaded PDF 77 to /workspaces/Wikistim-Summarization/00_source_data/downloaded_pdfs/pdf_77.pdf\n",
      "Failed to download PDF 82 from URL https://www.nejm.org/doi/pdf/10.1056/NEJM200008313430904?articleTools=true. Status Code: 403\n",
      "Failed to download PDF 82 from URL https://www.nejm.org/doi/pdf/10.1056/NEJM200008313430904?articleTools=true. Status Code: 403\n",
      "Failed to download PDF 82 from URL https://www.nejm.org/doi/pdf/10.1056/NEJM200008313430904?articleTools=true. Status Code: 403\n",
      "Maximum retry count reached for PDF 82. Download failed.\n",
      "Downloaded PDF 91 to /workspaces/Wikistim-Summarization/00_source_data/downloaded_pdfs/pdf_91.pdf\n",
      "Downloaded PDF 102 to /workspaces/Wikistim-Summarization/00_source_data/downloaded_pdfs/pdf_102.pdf\n",
      "Downloaded PDF 104 to /workspaces/Wikistim-Summarization/00_source_data/downloaded_pdfs/pdf_104.pdf\n",
      "Downloaded PDF 106 to /workspaces/Wikistim-Summarization/00_source_data/downloaded_pdfs/pdf_106.pdf\n",
      "Failed to download PDF 110 from URL https://www.minervamedica.it/en/getfreepdf/YmZDMnk5VW1rRTV0dVBqWFlYL2dOeHAzcUVHUUJSNVAreE5aVjZxZlUxeHNZZ1ZrRzlzNkx2TG1ydmJSeFEvcA%253D%253D/R02Y2012N03A0297.pdf. Status Code: 302\n",
      "Failed to download PDF 110 from URL https://www.minervamedica.it/en/getfreepdf/YmZDMnk5VW1rRTV0dVBqWFlYL2dOeHAzcUVHUUJSNVAreE5aVjZxZlUxeHNZZ1ZrRzlzNkx2TG1ydmJSeFEvcA%253D%253D/R02Y2012N03A0297.pdf. Status Code: 302\n",
      "Failed to download PDF 110 from URL https://www.minervamedica.it/en/getfreepdf/YmZDMnk5VW1rRTV0dVBqWFlYL2dOeHAzcUVHUUJSNVAreE5aVjZxZlUxeHNZZ1ZrRzlzNkx2TG1ydmJSeFEvcA%253D%253D/R02Y2012N03A0297.pdf. Status Code: 302\n",
      "Maximum retry count reached for PDF 110. Download failed.\n",
      "Download success rate: 82.86%\n"
     ]
    }
   ],
   "source": [
    "successful_downloads = 0  # Initialize a counter for successful downloads\n",
    "\n",
    "for idx, url in data_with_url['Full text link'].items():\n",
    "    retry_count = 0\n",
    "    while retry_count < max_retries:\n",
    "        try:\n",
    "            headers = {\"User-Agent\": user_agent}\n",
    "            response = requests.get(url, headers=headers, timeout=30)\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                # Define the filename based on the index\n",
    "                filename = f\"pdf_{idx}.pdf\"\n",
    "                # Define the full path to save the file\n",
    "                file_path = os.path.join(download_dir, filename)\n",
    "                \n",
    "                # Save the PDF to the specified directory with the indexed filename\n",
    "                with open(file_path, 'wb') as pdf_file:\n",
    "                    pdf_file.write(response.content)\n",
    "                \n",
    "                # Update the DataFrame with the downloaded PDF path\n",
    "                data_with_url.at[idx, 'Downloaded PDF Path'] = file_path\n",
    "                \n",
    "                print(f\"Downloaded PDF {idx} to {file_path}\")\n",
    "                successful_downloads += 1  # Increment the counter for successful downloads\n",
    "                break  # Successful download, exit retry loop\n",
    "            else:\n",
    "                print(f\"Failed to download PDF {idx} from URL {url}. Status Code: {response.status_code}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading PDF {idx} from URL {url}: {e}\")\n",
    "        \n",
    "        # Increment the retry count and wait before the next retry\n",
    "        retry_count += 1\n",
    "        time.sleep(5)  # Wait for 5 seconds before retrying\n",
    "\n",
    "    if retry_count >= max_retries:\n",
    "        print(f\"Maximum retry count reached for PDF {idx}. Download failed.\")\n",
    "\n",
    "# Calculate the success rate\n",
    "success_rate = (successful_downloads / len(data_with_url)) * 100\n",
    "\n",
    "# Print the result\n",
    "print(f\"Download success rate: {success_rate:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape text from downloaded pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5232/3042011097.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_with_url['full_article_text'] = \"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped processing //workspaces/Wikistim-Summarization/00_source_data/downloaded_pdfs/pdf_3.pdf due to an error: cannot open broken document\n",
      "Skipped processing //workspaces/Wikistim-Summarization/00_source_data/downloaded_pdfs/pdf_17.pdf due to an error: cannot open broken document\n",
      "Skipped processing //workspaces/Wikistim-Summarization/00_source_data/downloaded_pdfs/pdf_23.pdf due to an error: cannot open broken document\n",
      "Skipped processing //workspaces/Wikistim-Summarization/00_source_data/downloaded_pdfs/pdf_27.pdf due to an error: cannot open broken document\n",
      "Skipped processing //workspaces/Wikistim-Summarization/00_source_data/downloaded_pdfs/pdf_29.pdf due to an error: cannot open broken document\n",
      "Skipped processing //workspaces/Wikistim-Summarization/00_source_data/downloaded_pdfs/pdf_46.pdf due to an error: cannot open broken document\n",
      "Skipped processing //workspaces/Wikistim-Summarization/00_source_data/downloaded_pdfs/pdf_51.pdf due to an error: cannot open broken document\n",
      "Skipped processing //workspaces/Wikistim-Summarization/00_source_data/downloaded_pdfs/pdf_62.pdf due to an error: cannot open broken document\n",
      "Skipped processing //workspaces/Wikistim-Summarization/00_source_data/downloaded_pdfs/pdf_68.pdf due to an error: cannot open broken document\n",
      "Skipped processing //workspaces/Wikistim-Summarization/00_source_data/downloaded_pdfs/pdf_77.pdf due to an error: cannot open broken document\n",
      "Skipped processing //workspaces/Wikistim-Summarization/00_source_data/downloaded_pdfs/pdf_91.pdf due to an error: cannot open broken document\n",
      "Successfully scraped text from 18 out of 35 papers (51.43% success rate)\n"
     ]
    }
   ],
   "source": [
    "data_with_url['full_article_text'] = \"\"\n",
    "\n",
    "\n",
    "for idx, row in data_with_url.iterrows():\n",
    "    pdf_filename = row['Downloaded PDF Path']\n",
    "    if pdf_filename and pdf_filename.endswith(\".pdf\"):  # Check if PDF filename is not empty and ends with .pdf\n",
    "        pdf_path = f\"/{pdf_filename}\"  # Add the prefix to the PDF path\n",
    "        try:\n",
    "            doc = fitz.open(pdf_path)\n",
    "            # Extract text from all pages and join them into a single string\n",
    "            full_text = \"\"\n",
    "            for page in doc:\n",
    "                full_text += page.get_text()\n",
    "            \n",
    "            # Check if the extracted text is truly empty (no visible characters)\n",
    "            if full_text.strip():\n",
    "                # Update the DataFrame with the extracted text\n",
    "                data_with_url.at[idx, 'full_article_text'] = full_text\n",
    "            else:\n",
    "                print(f\"Skipped processing {pdf_path} because extracted text is empty.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Skipped processing {pdf_path} due to an error: {e}\")\n",
    "            continue  # Skip this document and move to the next one\n",
    "\n",
    "# Filter out rows where 'full_article_text' is truly empty\n",
    "filtered_data = data_with_url[data_with_url['full_article_text'].str.strip() != \"\"]\n",
    "\n",
    "# Calculate the number of successfully scraped texts\n",
    "successful_scrapes = filtered_data.shape[0]\n",
    "\n",
    "# Calculate the total number of papers\n",
    "total_papers = len(data_with_url)\n",
    "\n",
    "# Calculate the percentage of successful scrapes\n",
    "success_percentage = (successful_scrapes / total_papers) * 100\n",
    "\n",
    "# Print the result\n",
    "print(f\"Successfully scraped text from {successful_scrapes} out of {total_papers} papers ({success_percentage:.2f}% success rate)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimally clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PUBLICATION INFORMATION</th>\n",
       "      <th>Author(s)</th>\n",
       "      <th>Title</th>\n",
       "      <th>Journal</th>\n",
       "      <th>Volume, issue, pages</th>\n",
       "      <th>Year</th>\n",
       "      <th>Full text link</th>\n",
       "      <th>PUBMED link</th>\n",
       "      <th>STUDY DESCRIPTION AND METHODS</th>\n",
       "      <th>Study design</th>\n",
       "      <th>...</th>\n",
       "      <th>Facility type</th>\n",
       "      <th>DATA EXTRACTION</th>\n",
       "      <th>Awaiting completion. You may use the above link to download a CSV</th>\n",
       "      <th>Checked out by/date due</th>\n",
       "      <th>Submitted by/date submitted</th>\n",
       "      <th>Submission reviewed by/date reviewed</th>\n",
       "      <th>Unnamed: 214</th>\n",
       "      <th>Unnamed: 215</th>\n",
       "      <th>Downloaded PDF Path</th>\n",
       "      <th>full_article_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>Al-Kaisy A, Van Buyten JP, Carganillo R, Caraw...</td>\n",
       "      <td>10 kHz SCS therapy for chronic pain, effects o...</td>\n",
       "      <td>Sci Rep</td>\n",
       "      <td>9(1):11441</td>\n",
       "      <td>2019</td>\n",
       "      <td>https://www.nature.com/articles/s41598-019-477...</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pubmed/31391503</td>\n",
       "      <td></td>\n",
       "      <td>Post hoc analysis of data from two published s...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Anand Rotte/3 Sept 2019</td>\n",
       "      <td>JBS/finalized May 2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/workspaces/Wikistim-Summarization/00_source_d...</td>\n",
       "      <td>1 Scientific RepoRtS |         (2019) 9:11441 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 218 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  PUBLICATION INFORMATION                                          Author(s)  \\\n",
       "0                          Al-Kaisy A, Van Buyten JP, Carganillo R, Caraw...   \n",
       "\n",
       "                                               Title  Journal  \\\n",
       "0  10 kHz SCS therapy for chronic pain, effects o...  Sci Rep   \n",
       "\n",
       "  Volume, issue, pages  Year  \\\n",
       "0           9(1):11441  2019   \n",
       "\n",
       "                                      Full text link  \\\n",
       "0  https://www.nature.com/articles/s41598-019-477...   \n",
       "\n",
       "                                    PUBMED link STUDY DESCRIPTION AND METHODS  \\\n",
       "0  https://www.ncbi.nlm.nih.gov/pubmed/31391503                                 \n",
       "\n",
       "                                        Study design  ... Facility type  \\\n",
       "0  Post hoc analysis of data from two published s...  ...           NaN   \n",
       "\n",
       "  DATA EXTRACTION  \\\n",
       "0                   \n",
       "\n",
       "  Awaiting completion. You may use the above link to download a CSV  \\\n",
       "0                                                NaN                  \n",
       "\n",
       "  Checked out by/date due Submitted by/date submitted  \\\n",
       "0                     NaN     Anand Rotte/3 Sept 2019   \n",
       "\n",
       "  Submission reviewed by/date reviewed Unnamed: 214 Unnamed: 215  \\\n",
       "0               JBS/finalized May 2020          NaN          NaN   \n",
       "\n",
       "                                 Downloaded PDF Path  \\\n",
       "0  /workspaces/Wikistim-Summarization/00_source_d...   \n",
       "\n",
       "                                   full_article_text  \n",
       "0  1 Scientific RepoRtS |         (2019) 9:11441 ...  \n",
       "\n",
       "[1 rows x 218 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_with_full_text = filtered_data[~filtered_data['full_article_text'].isnull()]\n",
    "data_with_full_text = data_with_full_text.replace(r'\\n',' ', regex=True) \n",
    "data_with_full_text.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save text to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_full_text.to_csv('/workspaces/Wikistim-Summarization/00_source_data/uncleaned_text.csv', index=False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate average token length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Average Token Length: 32586.833333333332\n"
     ]
    }
   ],
   "source": [
    "paper_data = pd.read_csv('/workspaces/Wikistim-Summarization/00_source_data/uncleaned_text.csv')\n",
    "\n",
    "def average_token_length(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    token_lengths = [len(token) for token in tokens]\n",
    "    if len(token_lengths) > 0:\n",
    "        return sum(token_lengths)\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "\n",
    "paper_data['Token_Length'] = paper_data['full_article_text'].apply(average_token_length)\n",
    "overall_average = paper_data['Token_Length'].mean()\n",
    "print(\"Overall Average Token Length:\", overall_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
